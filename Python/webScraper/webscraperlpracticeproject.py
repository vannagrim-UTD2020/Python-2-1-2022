# -*- coding: utf-8 -*-
"""WebScraperlPracticeProject.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1YQ7-IenPjZ4TqHruBhXG4uKXGpwlUQgp
"""

import requests
import pandas as pd
from bs4 import BeautifulSoup


x = requests.get('http://quotes.toscrape.com/')
soup = BeautifulSoup(x.text)

#get all of the quotes from the link
for i in soup.findAll("div",{"class":"quote"}):
    print((i.find("span",{"class":"text"})).text)

#scrape the authors. 
for i in soup.findAll("div",{"class":"quote"}):
    print((i.find("small",{"class":"author"})).text)

#scrape anything else we can
for i in soup.findAll("div",{"class":"tags"}):
    print((i.find("meta"))['content'])

quotes = []
authors = []
tags = []

for pages in range(1,10):    
  x = requests.get('http://quotes.toscrape.com/page/'+str(pages)) 
  soup = BeautifulSoup(x.text)    
    
for i in soup.findAll("div",{"class":"quote"}):
        quotes.append((i.find("span",{"class":"text"})).text)  
   
for j in soup.findAll("div",{"class":"quote"}):
        authors.append((j.find("small",{"class":"author"})).text)    
        for k in soup.findAll("div",{"class":"tags"}):
          tags.append((k.find("meta"))['content'])

finaldx = pd.DataFrame(
    {'Quotes':quotes,
     'Authors':authors,
    
    })
print(finaldx)